```markdown
# News Analysis Automation

A comprehensive project for automating news article analysis, integrating web scraping, entity extraction, sentiment analysis, and MongoDB for data storage. The project is containerized using Docker and provides an intuitive interface with Streamlit.


## Features
- ğŸŒ Web Scraping: Extracts article content using `news_scraper.py` with BeautifulSoup.
- ğŸ§  Named Entity Recognition (NER): Extracts entities using spaCy.
- ğŸ˜Š Sentiment Analysis: Categorizes sentiments using VADER.
- ğŸ—‚ï¸ Database Storage: Saves processed data in MongoDB with `dbstore.py`.
- ğŸ“Š Interactive Dashboard: User-friendly Streamlit interface.
- ğŸ³ Containerized Setup: Dockerized for easy deployment.


## Installation

### Prerequisites
- Python 3.9+
- Docker and Docker Compose

### Steps
1. Clone the repository:
   ```bash
   git clone https://github.com/Vinay45454/News_Analysis_Project
   cd News_Analysis_Project
   ```
2. Add a `.env` file with MongoDB credentials (if required).
3. Build and start Docker containers:
   ```bash
   docker-compose up --build
   ```
4. Access the Streamlit interface at:
   ```
   http://localhost:8501
   ```

---

## Directory Structure
```
ğŸ“ Project Root
â”œâ”€â”€ .env                     # Environment variables
â”œâ”€â”€ Data Science Project Assessment.pdf  # Project brief
â”œâ”€â”€ dbstore.py               # MongoDB storage logic
â”œâ”€â”€ docker-compose.yml       # Docker Compose configuration
â”œâ”€â”€ Dockerfile               # Dockerfile for app containerization
â”œâ”€â”€ entity_extraction.py     # Entity extraction using spaCy
â”œâ”€â”€ news_analysis_report.docx  # Detailed project report
â”œâ”€â”€ news_scraper.py          # Scrapes articles from URLs
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ sentiment_analysis.py    # Sentiment analysis with VADER
```

---

## Usage
1. Input: 
   - Enter a URL or paste article text into the Streamlit interface.
2. Processing:
   - `news_scraper.py`: Scrapes and cleans HTML content.
   - `entity_extraction.py`: Identifies entities (names, locations, etc.).
   - `sentiment_analysis.py`: Performs sentiment analysis.
   - `dbstore.py`: Saves processed data in MongoDB.
3. Output: 
   - Visualized results in the interface.
   - Data saved for future analysis.

---

## Technologies Used
- Python Libraries: 
  - `spaCy`, `vaderSentiment`, `BeautifulSoup`, `pymongo`, `streamlit`
- MongoDB: For persistent storage.
- Docker: For containerized deployment.
- Streamlit: For creating an interactive dashboard.

---

## Future Improvements
- ğŸ” Advanced NLP Models: Use transformer models like BERT for improved accuracy.
- â³ Dynamic Content Handling: Integrate Selenium for JavaScript-heavy websites.
- ğŸ“ˆ Feedback Loop: Regularly refine NLP accuracy based on user feedback.

---


## Contact
- Name: Vinay Tiwari
- Email: tiwarivinay9310@gmail.com  
```  
